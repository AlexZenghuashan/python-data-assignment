import csv
import codecs
import pandas as pd
import requests
from bs4 import BeautifulSoup
url = 'https://www.qidian.com/all?chanId=2&subCateId=5&size=1&action=0&orderId=&vip=0&month=3&update=1&style=1&pageSize=20&siteid=1&pubflag=0&hiddenField=0&page=1'
url_list=[]
for i in range(0,12):
    page_number=str(i+1)
    url2 ='https://www.qidian.com/all?chanId=2&subCateId=5&size=1&action=0&orderId=&page=1&vip=0&month=3&update=1&style=1&pageSize=20&siteid=1&pubflag=0&hiddenField=&page='+ page_number
    url_list.append(url2)

r = requests.get(url)
r.encoding = 'utf-8'
data = BeautifulSoup(r.text, 'lxml')
content = data.find('div', attrs={'class':'book-img-text'})
lis = content.find_all('li')
def scrape_one_page(url):
    r = requests.get(url)
    r.encoding = 'utf-8'
    data = BeautifulSoup(r.text, 'lxml')
    content = data.find('div', attrs={'class':'book-img-text'})
    lis = content.find_all('li')
    all_content = []
    for li in lis:
        bookname = li.find('h4').text
        authors = li.find('a', attrs={'class':'name'}).text
        types = li.find('a', attrs={'class':'go-sub-type'}).text
        condition = li.find('span').text
        introduction = li.find('p', attrs={'class':'intro'}).text.replace('\r','')
        all_content.append([bookname,authors,types,condition,introduction])
    return all_content 
all_data = []
for url in url_list:
    data = scrape_one_page(url)
    all_data.extend(data)
with open('assignment1_Alex.csv', 'w', newline = '') as file:
    header=['name','author','type','condition','introduction']
    writer = csv.writer(file)
    writer.writerow(header)
    writer.writerows(all_data) 